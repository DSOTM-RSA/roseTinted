ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_gridperf2 <- h2o.getGrid(grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE)
gbm_gridperf2@summary_table[1,]
install.packages("rbokeh")
library(sparklyr)
library(dplyr)
library(babynames)
library(ggplot2)
library(dygraphs)
library(rbokeh)
install.packages("dygraphs")
sc <- spark_connect(master = "local")
babynames_tbl <- copy_to(sc, babynames, "babynames")
applicants_tbl <- copy_to(sc, applicants, "applicants")
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0))
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% collect()
View(birthsYearly)
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
View(birthsYearly)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
install.packages("dygraphs")
library(dygraphs)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex) %>% collect()
View(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
yearlyNames_tbl <- filteredNames_tbl %>%
group_by(year, name, sex) %>%
summarize(count = as.numeric(sum(n)))
sdf_register(yearlyNames_tbl, "yearlyNames")
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
View(birthsYearly)
data("babynames")
data("babynames")
View(babynames)
res <-babynames %>% filter(name=="Mary")
View(res)
res <-babynames %>% filter(name=="Mary" | sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "F")
View(res)
plot(res$year,res$prop)
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Beyonce" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Salvador" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Daniel" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="George" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="John" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Paul" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Jennifer" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Audrey" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Marilyn" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Elvis" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Michael" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Rupert" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Gordon" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Donald" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(year >= 1980)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) M %>% arrange(sex,rank)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank) %>% select(name,sex,rank)
View(res)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
View(topNames_tbl)
View(topNames1986Yearly)
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 4) %>% arrange(sex,rank) %>% select(name,sex,rank)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, prop, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
plot(cars)
plot(cars)
plot(cars)
knit_with_parameters('~/Research/testpy.Rmd')
plot(cars)
plot(cars)
plot(cars)
plot(cars)
xdata = c(1 ,5, 10, 20, 100)
> ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
xdata = c(1 ,5, 10, 20, 100)
ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
library(ggplot2)
ggplot(dat,aes(x=xdata,y=ydata)) +
geom_point() +
geom_smooth(method="nls", formula=y ~ p1+p2*x^2, se=FALSE,
start=list(p1=p1,p2=p2))
install.packages(c("backports", "curl", "earth", "janeaustenr", "R.matlab", "RcppArmadillo", "reshape", "reshape2", "semTools", "texreg"))
plot(cars)
plot(cars)
install.packages(c("enpls", "janeaustenr", "lava", "MCMCpack", "Rcmdr", "stochvol"))
library(purrr)
library(magrittr)
test.matrix <- matrix(1:6, nrow=2, ncol = 3,
dimnames = list(c('r1', 'r2'),
c('c1', 'c2', 'c3')))
list('a' = test.matrix) %>% map(function(x){x['r2', 'c1']})
View(test.matrix)
list('a' = test.matrix) %>% map(function(x){x[1, 2]})
list('a' = test.matrix) %>% map(function(x){x[1:2, 2]})
list('a' = test.matrix) %>% map(function(x){x[1:2, ]})
library(plyr)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
dataTable <- read.table("data/MAP_dat.tsv",header=T) # read in count data
library(purrr)
sampled_dt <- dataTable %>% group_by(depth) %>% nest() %>% mutate(n=2) %>% # example of using purrr for sampling
mutate(samp=map2(data,n,sample_n,replace=TRUE)) %>% select(depth,samp) %>% unnest()
View(sampled_dt)
mat_dt <- dataTable %>% group_by(depth) %>% nest()
View(mat_dt)
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(.,function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest()
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data)
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[1:2, ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[, ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[ ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[][1:2,]})
dataTable %>% group_by(depth)
dataTable %>% group_by(depth) %>% .[1:2,]
dataTable %>% group_by(depth) %>% .[,5:10]
out<-dataTable %>% group_by(depth) %>% .[,6:10]
str(out)
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix()
View(out)
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix() %>% nest()
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix() %>% dist()
str(out)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
partitions2 <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5))
partitions2 <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
training <- as_h2o_frame(sc, mtcars_tbl)
install.packages(c("acepack", "checkpoint", "drat", "openssl", "pbapply", "plotmo", "proto", "qgraph", "R.oo", "rprojroot", "sjmisc", "sjPlot", "sjstats", "survival", "tidytext"))
devtools::install_github("leonawicz/mapmate")
library(mapmate)
library(dplyr)
library(RColorBrewer)
pal <- rev(brewer.pal(11, "RdYlBu"))
data(annualtemps)
data(borders)
data(bathymetry)
id <- "frameID"
temps <- mutate(annualtemps, frameID = Year - min(Year) + 1) %>% filter(frameID ==
1)  # subset to first frame
brdrs <- mutate(borders, frameID = 1)
bath <- mutate(bathymetry, frameID = 1)
View(temps)
View(annualtemps)
save_map(temps, id = id, ortho = FALSE, col = "dodgerblue", type = "points",
save.plot = FALSE, return.plot = TRUE)
save_map(temps, id = id, col = "#FF4500", type = "points", save.plot = FALSE,
return.plot = TRUE)
save_map(bath, id = id, type = "points", save.plot = FALSE, return.plot = TRUE)
View(brdrs)
save_map(brdrs, id = id, type = "maplines", save.plot = FALSE, return.plot = TRUE)
save_map(brdrs, id = id, lon = -70, lat = 40, rotation.axis = 0, type = "maplines",
save.plot = FALSE, return.plot = TRUE)
save_map(bath, z.name = "z", id = id, col = pal, type = "maptiles", save.plot = FALSE,
return.plot = TRUE)
View(bath)
View(temps)
View(annualtemps)
save_map(bath, z.name = "z", id = id, col = pal, type = "density", save.plot = FALSE,
return.plot = TRUE)
save_map(bath, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
save.plot = FALSE, return.plot = TRUE)
save_map(bath, z.name = "z", id = id, col = pal, type = "density", contour = "only",
save.plot = FALSE, return.plot = TRUE)
save_map(temps, id = id, col = "red", type = "points", contour = "overlay",
save.plot = FALSE, return.plot = TRUE)
save_map(temps, id = id, col = "blue", type = "points", contour = "only", save.plot = FALSE,
return.plot = TRUE)
save_map(temps, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
save.plot = FALSE, return.plot = TRUE)
save_map(temps, id = id, col = pal, type = "density", contour = "overlay", save.plot = FALSE,
return.plot = TRUE)
save_map(temps, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
density.geom = "tile", save.plot = FALSE, return.plot = TRUE)
save_map(temps, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
density.geom = "tile", save.plot = FALSE, return.plot = TRUE)
save_map(temps, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
density.geom = "polygon", save.plot = FALSE, return.plot = TRUE)
save_map(bath, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
density.geom = "tile", save.plot = FALSE, return.plot = TRUE)
save_map(bath, z.name = "z", id = id, col = pal, type = "density", contour = "overlay",
density.geom = "polygon", save.plot = FALSE, return.plot = TRUE)
library(rworldmap)
library(rworldxtra)  # required for 'high' resolution map
library(maptools)  # required for fortify to work
# also recommend installing rgeos
install.packages("rworldmap")
install.packages("rworldxtra")
install.packages("rgeos")
library(rworldmap)
library(rworldxtra)  # required for 'high' resolution map
library(maptools)  # required for fortify to work
# also recommend installing rgeos
spdf <- joinCountryData2Map(countryExData, mapResolution = "high")
spdf@data$id <- rownames(spdf@data)
bio <- ggplot2::fortify(spdf, region = "id") %>% left_join(subset(spdf@data,
select = c(id, BIODIVERSITY)), by = "id") %>% mutate(frameID = 1) %>% rename(lon = long)
gpclibPermit()
bio <- ggplot2::fortify(spdf, region = "id") %>% left_join(subset(spdf@data,
select = c(id, BIODIVERSITY)), by = "id") %>% mutate(frameID = 1) %>% rename(lon = long)
View(bio)
library(raster)
proj4 <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +to wgs84=0,0,0"
z <- "BIODIVERSITY"
# 1-degree resolution, still somewhat coarse
r <- raster(extent(-180, 180, -90, 90), nrow = 180, ncol = 360, proj4)
bio2 <- rasterize(spdf, r, field = z) %>% rasterToPoints %>% tbl_df() %>% setNames(c("lon",
"lat", z)) %>% mutate(frameID = 1)
clrs <- c("royalblue", "purple", "orange", "yellow")
save_map(bio, z.name = z, id = id, lon = -10, lat = 20, col = pal, type = "polygons",
save.plot = FALSE, return.plot = TRUE)
clrs <- c("royalblue", "purple", "orange", "yellow")
save_map(bio, z.name = z, id = id, lon = -10, lat = 20, col = pal, type = "polygons",
save.plot = FALSE, return.plot = TRUE)
save_map(bio2, z.name = z, id = id, lon = -10, lat = 20, col = pal, type = "maptiles",
save.plot = FALSE, return.plot = TRUE)
clrs <- c("royalblue", "purple", "orange", "yellow")
save_map(bio, z.name = z, id = id, lon = -10, lat = 20, col = pal, type = "polygons",
save.plot = FALSE, return.plot = TRUE)
library(mlbench)
library(e1071)
data("HouseVotes84")
View(HouseVotes84)
model <- naiveBayes(Class ~ ., data = HouseVotes84)
print(model)
pn <- vector(mode="numeric",length=16)
for (i in 1:16) {
pn[i] <- model$tables[[i]][1,1]
}
dem_data <- matrix(data = NA, nrow = 25, ncol = 17)
for( i in 1:25){
dem_data[i,] <- c("democrat",rbinom(16,1,pn))
}
View(dem_data)
dem_data <- data.frame(dem_data)
View(dem_data)
levels(dem_data[,1]) <- c("democrat","republican")
dem_data[,1] <- factor(dem_data[,1],levels=c("democrat","republican"))
View(dem_data)
for(i in 2:17){
levels(dem_data[,i]) <- c("y","n")
}
View(dem_data)
names(dem_data) <- c("Class","V1","V2","V3","V4","V5","V6","V7","V8",
"V9","V10","V11","V12","V13","V14","V15","V16")
head(dem_data,2)
dim(dem_data)
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
# function to compute the conditional probability
# that a member of a party will cast
# a 'yes' vote for a particular issue.
# The probability is based on all members of the
# party who actually cast a vote on the issue (ignores NAs).
p_y_col_class <- function(col,cls){
sum_y<-sum(HouseVotes84[,col]=='y' &
HouseVotes84$Class==cls,na.rm = TRUE)
sum_n<-sum(HouseVotes84[,col]=='n' &
HouseVotes84$Class==cls,na.rm = TRUE)
return(sum_y/(sum_y+sum_n))}
#impute missing values.
for (i in 2:ncol(HouseVotes84)) {
if(sum(is.na(HouseVotes84[,i])>0)) {
c1 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='democrat',arr.ind = TRUE)
c2 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='republican',arr.ind = TRUE)
HouseVotes84[c1,i] <-
ifelse(runif(na_by_col_class(i,'democrat'))<
p_y_col_class(i,'democrat'),'y','n')
HouseVotes84[c2,i] <-
ifelse(runif(na_by_col_class(i,'republican'))<
p_y_col_class(i,'republican'),'y','n')}
}
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
# function to compute the conditional probability
# that a member of a party will cast
# a 'yes' vote for a particular issue.
# The probability is based on all members of the
# party who actually cast a vote on the issue (ignores NAs).
p_y_col_class <- function(col,cls){
sum_y<-sum(HouseVotes84[,col]=='y' &
HouseVotes84$Class==cls,na.rm = TRUE)
sum_n<-sum(HouseVotes84[,col]=='n' &
HouseVotes84$Class==cls,na.rm = TRUE)
return(sum_y/(sum_y+sum_n))}
for (i in 2:ncol(HouseVotes84)) {
if(sum(is.na(HouseVotes84[,i])>0)) {
c1 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='democrat',arr.ind = TRUE)
c2 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='republican',arr.ind = TRUE)
HouseVotes84[c1,i] <-
ifelse(runif(na_by_col_class(i,'democrat'))<
p_y_col_class(i,'democrat'),'y','n')
HouseVotes84[c2,i] <-
ifelse(runif(na_by_col_class(i,'republican'))<
p_y_col_class(i,'republican'),'y','n')}
}
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))
)
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}))
na_by_col_class <-
function (col,cls){return(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
p_y_col_class <- function(col,cls){
sum_y<-sum(HouseVotes84[,col]=='y' &
HouseVotes84$Class==cls,na.rm = TRUE)
sum_n<-sum(HouseVotes84[,col]=='n' &
HouseVotes84$Class==cls,na.rm = TRUE)
return(sum_y/(sum_y+sum_n))}
na_by_col_class <-
function (col,cls){(sum(is.na(HouseVotes84[,col] &
HouseVotes84$Class==cls))}
na_by_col_class <- function (col,cls){return(sum(is.na(HouseVotes84[,col]) & HouseVotes84$Class==cls))}
p_y_col_class <- function(col,cls){
sum_y<-sum(HouseVotes84[,col]=='y' &
HouseVotes84$Class==cls,na.rm = TRUE)
sum_n<-sum(HouseVotes84[,col]=='n' &
HouseVotes84$Class==cls,na.rm = TRUE)
return(sum_y/(sum_y+sum_n))}
for (i in 2:ncol(HouseVotes84)) {
if(sum(is.na(HouseVotes84[,i])>0)) {
c1 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='democrat',arr.ind = TRUE)
c2 <- which(is.na(HouseVotes84[,i])& HouseVotes84$Class=='republican',arr.ind = TRUE)
HouseVotes84[c1,i] <-
ifelse(runif(na_by_col_class(i,'democrat'))<
p_y_col_class(i,'democrat'),'y','n')
HouseVotes84[c2,i] <-
ifelse(runif(na_by_col_class(i,'republican'))<
p_y_col_class(i,'republican'),'y','n')}
}
View(HouseVotes84)
votes <- HouseVotes84
votes$Class <- ifelse(votes$Class == "democrat", 0, 1)
votes[,2:17] <- sapply(votes[,2:17],
function(x){ifelse(x == "n", 1, 0)})
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
votes_tbl <- copy_to(sc, votes,overwrite=TRUE)
head(votes_tbl)
partitions <- votes_tbl %>%
sdf_partition(training = 0.5,
test = 0.5, seed = 1099)
head(partitions$training)
# pick out the feature variables.
X_names <- names(votes[,2:17])
# Fit model
nb_spark_model <- ml_naive_bayes(partitions$training,
response= "Class",
features = X_names)
nb_spark_model
nb_test_predict <- predict(nb_model,testHouseVotes84[,-1])
#confusion matrix
table(pred=nb_test_predict,true=testHouseVotes84$Class)
install.packages(c("caret", "dygraphs", "htmlwidgets", "hunspell", "knitr", "scales"))
setwd("~/Research/cvCells/macro-tests")
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
source('~/Research/cvCells/macro-tests/haralick.R', echo=TRUE)
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
source('~/Research/cvCells/macro-tests/modelBuilding.R', echo=TRUE)
dat.H2o.train <- as_h2o_frame(sc, features_tbl)
y <- "rNames_tag"
x <- setdiff(names(dat.H2o.train), y)
dat.H2o.train[,y] <- as.factor(dat.H2o.train[,y])
splits <- h2o.splitFrame(dat.H2o.train, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model) # metrics on full data-set : potenital peak accuracy
h2o.confusionMatrix(rf_model, valid = TRUE) # metrics on test set : production setting
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model) # metrics on full data-set : potenital peak accuracy
