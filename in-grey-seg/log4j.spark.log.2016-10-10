16/10/10 14:38:42 INFO SparkContext: Running Spark version 1.6.2
16/10/10 14:38:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/10/10 14:38:44 INFO SecurityManager: Changing view acls to: danny
16/10/10 14:38:44 INFO SecurityManager: Changing modify acls to: danny
16/10/10 14:38:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(danny); users with modify permissions: Set(danny)
16/10/10 14:38:46 INFO Utils: Successfully started service 'sparkDriver' on port 51182.
16/10/10 14:38:48 INFO Slf4jLogger: Slf4jLogger started
16/10/10 14:38:48 INFO Remoting: Starting remoting
16/10/10 14:38:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@127.0.0.1:51183]
16/10/10 14:38:48 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51183.
16/10/10 14:38:48 INFO SparkEnv: Registering MapOutputTracker
16/10/10 14:38:49 INFO SparkEnv: Registering BlockManagerMaster
16/10/10 14:38:49 INFO DiskBlockManager: Created local directory at /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/blockmgr-c8c0b51c-15c4-4cc0-a32c-4b432bd509e0
16/10/10 14:38:49 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
16/10/10 14:38:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/10/10 14:38:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/10/10 14:38:49 INFO SparkUI: Started SparkUI at http://127.0.0.1:4040
16/10/10 14:38:50 INFO HttpFileServer: HTTP File server directory is /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/httpd-6db5af73-6676-4d15-b5cb-b8df8c94bc47
16/10/10 14:38:50 INFO HttpServer: Starting HTTP Server
16/10/10 14:38:50 INFO Utils: Successfully started service 'HTTP file server' on port 51184.
16/10/10 14:38:50 INFO SparkContext: Added JAR file:/Users/danny/.ivy2/jars/com.databricks_spark-csv_2.11-1.3.0.jar at http://127.0.0.1:51184/jars/com.databricks_spark-csv_2.11-1.3.0.jar with timestamp 1476103130146
16/10/10 14:38:50 INFO SparkContext: Added JAR file:/Users/danny/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar at http://127.0.0.1:51184/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1476103130148
16/10/10 14:38:50 INFO SparkContext: Added JAR file:/Users/danny/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar at http://127.0.0.1:51184/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1476103130150
16/10/10 14:38:50 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.3/Resources/library/sparklyr/java/sparklyr-1.6-2.10.jar at http://127.0.0.1:51184/jars/sparklyr-1.6-2.10.jar with timestamp 1476103130166
16/10/10 14:38:50 INFO Executor: Starting executor ID driver on host localhost
16/10/10 14:38:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51185.
16/10/10 14:38:50 INFO NettyBlockTransferService: Server created on 51185
16/10/10 14:38:50 INFO BlockManagerMaster: Trying to register BlockManager
16/10/10 14:38:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51185 with 511.1 MB RAM, BlockManagerId(driver, localhost, 51185)
16/10/10 14:38:50 INFO BlockManagerMaster: Registered BlockManager
16/10/10 14:38:53 INFO HiveContext: Initializing execution hive, version 1.2.1
16/10/10 14:38:53 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
16/10/10 14:38:53 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
16/10/10 14:38:54 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
16/10/10 14:38:54 INFO ObjectStore: ObjectStore, initialize called
16/10/10 14:38:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
16/10/10 14:38:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
16/10/10 14:38:54 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
16/10/10 14:38:56 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
16/10/10 14:38:58 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
16/10/10 14:38:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:38:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
16/10/10 14:39:01 INFO ObjectStore: Initialized ObjectStore
16/10/10 14:39:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
16/10/10 14:39:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
16/10/10 14:39:01 INFO HiveMetaStore: Added admin role in metastore
16/10/10 14:39:01 INFO HiveMetaStore: Added public role in metastore
16/10/10 14:39:02 INFO HiveMetaStore: No user is added in admin role, since config is empty
16/10/10 14:39:02 INFO HiveMetaStore: 0: get_all_databases
16/10/10 14:39:02 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_all_databases	
16/10/10 14:39:02 INFO HiveMetaStore: 0: get_functions: db=default pat=*
16/10/10 14:39:02 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
16/10/10 14:39:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:02 INFO SessionState: Created local directory: /var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/f3d67e9c-e3c9-41ff-a884-d403cb2c20f8_resources
16/10/10 14:39:02 INFO SessionState: Created HDFS directory: /tmp/hive/danny/f3d67e9c-e3c9-41ff-a884-d403cb2c20f8
16/10/10 14:39:02 INFO SessionState: Created local directory: /var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/danny/f3d67e9c-e3c9-41ff-a884-d403cb2c20f8
16/10/10 14:39:02 INFO SessionState: Created HDFS directory: /tmp/hive/danny/f3d67e9c-e3c9-41ff-a884-d403cb2c20f8/_tmp_space.db
16/10/10 14:39:02 INFO HiveContext: default warehouse location is /user/hive/warehouse
16/10/10 14:39:03 INFO HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
16/10/10 14:39:03 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
16/10/10 14:39:03 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
16/10/10 14:39:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
16/10/10 14:39:03 INFO ObjectStore: ObjectStore, initialize called
16/10/10 14:39:03 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
16/10/10 14:39:03 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
16/10/10 14:39:03 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
16/10/10 14:39:04 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
16/10/10 14:39:05 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
16/10/10 14:39:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
16/10/10 14:39:07 INFO ObjectStore: Initialized ObjectStore
16/10/10 14:39:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
16/10/10 14:39:07 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
16/10/10 14:39:07 INFO HiveMetaStore: Added admin role in metastore
16/10/10 14:39:07 INFO HiveMetaStore: Added public role in metastore
16/10/10 14:39:07 INFO HiveMetaStore: No user is added in admin role, since config is empty
16/10/10 14:39:08 INFO HiveMetaStore: 0: get_all_databases
16/10/10 14:39:08 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_all_databases	
16/10/10 14:39:08 INFO HiveMetaStore: 0: get_functions: db=default pat=*
16/10/10 14:39:08 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
16/10/10 14:39:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
16/10/10 14:39:08 INFO SessionState: Created local directory: /var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/875cb304-5f87-4cec-956b-ec8cf7f49cae_resources
16/10/10 14:39:08 INFO SessionState: Created HDFS directory: /tmp/hive/danny/875cb304-5f87-4cec-956b-ec8cf7f49cae
16/10/10 14:39:08 INFO SessionState: Created local directory: /var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/danny/875cb304-5f87-4cec-956b-ec8cf7f49cae
16/10/10 14:39:08 INFO SessionState: Created HDFS directory: /tmp/hive/danny/875cb304-5f87-4cec-956b-ec8cf7f49cae/_tmp_space.db
16/10/10 14:39:10 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:39:10 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:40:23 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:40:23 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:40:24 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:40:24 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:40:24 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
16/10/10 14:40:24 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:40:24 INFO DAGScheduler: Missing parents: List()
16/10/10 14:40:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:56), which has no missing parents
16/10/10 14:40:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.4 KB, free 5.4 KB)
16/10/10 14:40:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.0 KB, free 8.4 KB)
16/10/10 14:40:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:40:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
16/10/10 14:40:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:56)
16/10/10 14:40:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
16/10/10 14:40:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2396 bytes)
16/10/10 14:40:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/10/10 14:40:24 INFO Executor: Fetching http://127.0.0.1:51184/jars/sparklyr-1.6-2.10.jar with timestamp 1476103130166
16/10/10 14:40:25 INFO Utils: Fetching http://127.0.0.1:51184/jars/sparklyr-1.6-2.10.jar to /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/fetchFileTemp1207758832970528353.tmp
16/10/10 14:40:25 INFO Executor: Adding file:/private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/sparklyr-1.6-2.10.jar to class loader
16/10/10 14:40:25 INFO Executor: Fetching http://127.0.0.1:51184/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1476103130150
16/10/10 14:40:25 INFO Utils: Fetching http://127.0.0.1:51184/jars/com.univocity_univocity-parsers-1.5.1.jar to /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/fetchFileTemp2165029304006393712.tmp
16/10/10 14:40:25 INFO Executor: Adding file:/private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/com.univocity_univocity-parsers-1.5.1.jar to class loader
16/10/10 14:40:25 INFO Executor: Fetching http://127.0.0.1:51184/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1476103130148
16/10/10 14:40:25 INFO Utils: Fetching http://127.0.0.1:51184/jars/org.apache.commons_commons-csv-1.1.jar to /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/fetchFileTemp847673478864058204.tmp
16/10/10 14:40:25 INFO Executor: Adding file:/private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/org.apache.commons_commons-csv-1.1.jar to class loader
16/10/10 14:40:25 INFO Executor: Fetching http://127.0.0.1:51184/jars/com.databricks_spark-csv_2.11-1.3.0.jar with timestamp 1476103130146
16/10/10 14:40:25 INFO Utils: Fetching http://127.0.0.1:51184/jars/com.databricks_spark-csv_2.11-1.3.0.jar to /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/fetchFileTemp4486180164286778227.tmp
16/10/10 14:40:25 INFO Executor: Adding file:/private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/userFiles-0505b94d-7275-4852-ad55-37860fcbee71/com.databricks_spark-csv_2.11-1.3.0.jar to class loader
16/10/10 14:40:25 INFO GenerateUnsafeProjection: Code generated in 192.737301 ms
16/10/10 14:40:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1060 bytes result sent to driver
16/10/10 14:40:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 953 ms on localhost (1/1)
16/10/10 14:40:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/10/10 14:40:25 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 1.023 s
16/10/10 14:40:25 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 1.551891 s
16/10/10 14:40:25 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:40:25 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:40:26 INFO HiveMetaStore: 0: get_table : db=array tbl=dfs
16/10/10 14:40:26 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_table : db=array tbl=dfs	
16/10/10 14:41:31 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:41:31 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:41:31 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:41:31 INFO DAGScheduler: Got job 1 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:41:31 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:59)
16/10/10 14:41:31 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:41:31 INFO DAGScheduler: Missing parents: List()
16/10/10 14:41:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:56), which has no missing parents
16/10/10 14:41:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 13.8 KB)
16/10/10 14:41:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 16.8 KB)
16/10/10 14:41:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:41:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
16/10/10 14:41:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at map at utils.scala:56)
16/10/10 14:41:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
16/10/10 14:41:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:41:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
16/10/10 14:41:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1072 bytes result sent to driver
16/10/10 14:41:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (1/1)
16/10/10 14:41:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/10/10 14:41:31 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:59) finished in 0.009 s
16/10/10 14:41:31 INFO DAGScheduler: Job 1 finished: collect at utils.scala:59, took 0.019615 s
16/10/10 14:41:46 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:41:46 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:41:46 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:41:46 INFO DAGScheduler: Got job 2 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:41:46 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:59)
16/10/10 14:41:46 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:41:46 INFO DAGScheduler: Missing parents: List()
16/10/10 14:41:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at map at utils.scala:56), which has no missing parents
16/10/10 14:41:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.4 KB, free 22.2 KB)
16/10/10 14:41:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 25.2 KB)
16/10/10 14:41:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:41:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
16/10/10 14:41:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at map at utils.scala:56)
16/10/10 14:41:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
16/10/10 14:41:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:41:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
16/10/10 14:41:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1072 bytes result sent to driver
16/10/10 14:41:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 5 ms on localhost (1/1)
16/10/10 14:41:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/10/10 14:41:46 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:41:46 INFO DAGScheduler: Job 2 finished: collect at utils.scala:59, took 0.012720 s
16/10/10 14:41:46 INFO HiveMetaStore: 0: get_table : db=array tbl=dfs
16/10/10 14:41:46 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_table : db=array tbl=dfs	
16/10/10 14:42:34 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:42:34 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:42:34 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:42:34 INFO DAGScheduler: Got job 3 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:42:34 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:59)
16/10/10 14:42:34 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:42:34 INFO DAGScheduler: Missing parents: List()
16/10/10 14:42:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at map at utils.scala:56), which has no missing parents
16/10/10 14:42:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.4 KB, free 30.7 KB)
16/10/10 14:42:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.0 KB, free 33.6 KB)
16/10/10 14:42:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:42:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
16/10/10 14:42:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at map at utils.scala:56)
16/10/10 14:42:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
16/10/10 14:42:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:42:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
16/10/10 14:42:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1072 bytes result sent to driver
16/10/10 14:42:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 4 ms on localhost (1/1)
16/10/10 14:42:34 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:59) finished in 0.004 s
16/10/10 14:42:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
16/10/10 14:42:34 INFO DAGScheduler: Job 3 finished: collect at utils.scala:59, took 0.012361 s
16/10/10 14:42:56 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:42:56 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:42:56 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:42:56 INFO DAGScheduler: Got job 4 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:42:56 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:59)
16/10/10 14:42:56 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:42:56 INFO DAGScheduler: Missing parents: List()
16/10/10 14:42:56 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at map at utils.scala:56), which has no missing parents
16/10/10 14:42:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.4 KB, free 39.1 KB)
16/10/10 14:42:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.0 KB, free 42.0 KB)
16/10/10 14:42:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:42:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
16/10/10 14:42:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at map at utils.scala:56)
16/10/10 14:42:56 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
16/10/10 14:42:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:42:56 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
16/10/10 14:42:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1072 bytes result sent to driver
16/10/10 14:42:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (1/1)
16/10/10 14:42:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
16/10/10 14:42:56 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:42:56 INFO DAGScheduler: Job 4 finished: collect at utils.scala:59, took 0.031340 s
16/10/10 14:43:04 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:43:04 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:43:04 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:43:04 INFO DAGScheduler: Got job 5 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:43:04 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:59)
16/10/10 14:43:04 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:43:04 INFO DAGScheduler: Missing parents: List()
16/10/10 14:43:04 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at map at utils.scala:56), which has no missing parents
16/10/10 14:43:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.4 KB, free 47.5 KB)
16/10/10 14:43:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.0 KB, free 50.4 KB)
16/10/10 14:43:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:43:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
16/10/10 14:43:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at map at utils.scala:56)
16/10/10 14:43:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
16/10/10 14:43:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:43:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
16/10/10 14:43:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1072 bytes result sent to driver
16/10/10 14:43:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 4 ms on localhost (1/1)
16/10/10 14:43:04 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
16/10/10 14:43:04 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:43:04 INFO DAGScheduler: Job 5 finished: collect at utils.scala:59, took 0.013152 s
16/10/10 14:43:04 INFO HiveMetaStore: 0: get_table : db=array tbl=dfs
16/10/10 14:43:04 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_table : db=array tbl=dfs	
16/10/10 14:45:53 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:45:53 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:45:53 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:45:53 INFO DAGScheduler: Got job 6 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:45:53 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:59)
16/10/10 14:45:53 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:45:53 INFO DAGScheduler: Missing parents: List()
16/10/10 14:45:53 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[29] at map at utils.scala:56), which has no missing parents
16/10/10 14:45:53 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.4 KB, free 55.9 KB)
16/10/10 14:45:53 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.0 KB, free 58.9 KB)
16/10/10 14:45:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:45:53 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
16/10/10 14:45:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[29] at map at utils.scala:56)
16/10/10 14:45:53 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
16/10/10 14:45:53 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:45:53 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
16/10/10 14:45:53 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1072 bytes result sent to driver
16/10/10 14:45:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (1/1)
16/10/10 14:45:53 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
16/10/10 14:45:53 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:59) finished in 0.006 s
16/10/10 14:45:53 INFO DAGScheduler: Job 6 finished: collect at utils.scala:59, took 0.020523 s
16/10/10 14:46:27 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:46:27 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:46:27 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:46:27 INFO DAGScheduler: Got job 7 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:46:27 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:59)
16/10/10 14:46:27 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:46:27 INFO DAGScheduler: Missing parents: List()
16/10/10 14:46:27 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at map at utils.scala:56), which has no missing parents
16/10/10 14:46:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 5.4 KB, free 64.3 KB)
16/10/10 14:46:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.0 KB, free 67.3 KB)
16/10/10 14:46:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:46:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
16/10/10 14:46:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at map at utils.scala:56)
16/10/10 14:46:27 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
16/10/10 14:46:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:46:27 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
16/10/10 14:46:27 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1072 bytes result sent to driver
16/10/10 14:46:27 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5 ms on localhost (1/1)
16/10/10 14:46:27 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:46:27 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
16/10/10 14:46:27 INFO DAGScheduler: Job 7 finished: collect at utils.scala:59, took 0.014651 s
16/10/10 14:46:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 61.8 KB, free 129.1 KB)
16/10/10 14:46:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.3 KB, free 148.4 KB)
16/10/10 14:46:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:51185 (size: 19.3 KB, free: 511.1 MB)
16/10/10 14:46:27 INFO SparkContext: Created broadcast 8 from textFile at TextFile.scala:30
16/10/10 14:47:22 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:47:22 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:47:22 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:47:22 INFO DAGScheduler: Got job 8 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:47:22 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:59)
16/10/10 14:47:22 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:47:22 INFO DAGScheduler: Missing parents: List()
16/10/10 14:47:22 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at map at utils.scala:56), which has no missing parents
16/10/10 14:47:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 5.4 KB, free 153.8 KB)
16/10/10 14:47:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.0 KB, free 156.8 KB)
16/10/10 14:47:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:47:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
16/10/10 14:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at map at utils.scala:56)
16/10/10 14:47:22 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
16/10/10 14:47:22 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:47:22 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
16/10/10 14:47:22 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1072 bytes result sent to driver
16/10/10 14:47:22 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (1/1)
16/10/10 14:47:22 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
16/10/10 14:47:22 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:47:22 INFO DAGScheduler: Job 8 finished: collect at utils.scala:59, took 0.017307 s
16/10/10 14:48:55 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:48:55 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:48:55 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:48:55 INFO DAGScheduler: Got job 9 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:48:55 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:59)
16/10/10 14:48:55 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:48:55 INFO DAGScheduler: Missing parents: List()
16/10/10 14:48:55 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[43] at map at utils.scala:56), which has no missing parents
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.4 KB, free 162.2 KB)
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KB, free 165.2 KB)
16/10/10 14:48:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[43] at map at utils.scala:56)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
16/10/10 14:48:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:48:55 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
16/10/10 14:48:55 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1072 bytes result sent to driver
16/10/10 14:48:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (1/1)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
16/10/10 14:48:55 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:59) finished in 0.006 s
16/10/10 14:48:55 INFO DAGScheduler: Job 9 finished: collect at utils.scala:59, took 0.014260 s
16/10/10 14:48:55 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:48:55 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:48:55 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:48:55 INFO DAGScheduler: Got job 10 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:48:55 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:59)
16/10/10 14:48:55 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:48:55 INFO DAGScheduler: Missing parents: List()
16/10/10 14:48:55 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at map at utils.scala:56), which has no missing parents
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.4 KB, free 170.6 KB)
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.0 KB, free 173.6 KB)
16/10/10 14:48:55 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at map at utils.scala:56)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
16/10/10 14:48:55 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2699 bytes)
16/10/10 14:48:55 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
16/10/10 14:48:55 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1072 bytes result sent to driver
16/10/10 14:48:55 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 3 ms on localhost (1/1)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
16/10/10 14:48:55 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:59) finished in 0.003 s
16/10/10 14:48:55 INFO DAGScheduler: Job 10 finished: collect at utils.scala:59, took 0.011630 s
16/10/10 14:48:55 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:48:55 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 208.5 KB, free 382.1 KB)
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 19.3 KB, free 401.4 KB)
16/10/10 14:48:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:51185 (size: 19.3 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO SparkContext: Created broadcast 12 from textFile at TextFile.scala:30
16/10/10 14:48:55 INFO FileInputFormat: Total input paths to process : 1
16/10/10 14:48:55 INFO SparkContext: Starting job: take at CsvRelation.scala:249
16/10/10 14:48:55 INFO DAGScheduler: Got job 11 (take at CsvRelation.scala:249) with 1 output partitions
16/10/10 14:48:55 INFO DAGScheduler: Final stage: ResultStage 11 (take at CsvRelation.scala:249)
16/10/10 14:48:55 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:48:55 INFO DAGScheduler: Missing parents: List()
16/10/10 14:48:55 INFO DAGScheduler: Submitting ResultStage 11 (/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T//RtmpI3wuED/file196a6e82aeb4.csv MapPartitionsRDD[50] at textFile at TextFile.scala:30), which has no missing parents
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.1 KB, free 404.6 KB)
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 1897.0 B, free 406.4 KB)
16/10/10 14:48:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:51185 (size: 1897.0 B, free: 511.1 MB)
16/10/10 14:48:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T//RtmpI3wuED/file196a6e82aeb4.csv MapPartitionsRDD[50] at textFile at TextFile.scala:30)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
16/10/10 14:48:55 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0,PROCESS_LOCAL, 2478 bytes)
16/10/10 14:48:55 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
16/10/10 14:48:55 INFO HadoopRDD: Input split: file:/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/RtmpI3wuED/file196a6e82aeb4.csv:0+651
16/10/10 14:48:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/10/10 14:48:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/10/10 14:48:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/10/10 14:48:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/10/10 14:48:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/10/10 14:48:55 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2478 bytes result sent to driver
16/10/10 14:48:55 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 138 ms on localhost (1/1)
16/10/10 14:48:55 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
16/10/10 14:48:55 INFO DAGScheduler: ResultStage 11 (take at CsvRelation.scala:249) finished in 0.139 s
16/10/10 14:48:55 INFO DAGScheduler: Job 11 finished: take at CsvRelation.scala:249, took 0.148916 s
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 208.5 KB, free 614.9 KB)
16/10/10 14:48:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.3 KB, free 634.3 KB)
16/10/10 14:48:55 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:51185 (size: 19.3 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO SparkContext: Created broadcast 14 from textFile at TextFile.scala:30
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 19
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 12
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 11
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 10
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 9
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 8
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 7
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 6
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 5
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 4
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 3
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 2
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:51185 in memory (size: 1897.0 B, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 24
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:51185 in memory (size: 19.3 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 23
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 22
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 21
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 20
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 18
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:51185 in memory (size: 19.3 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 17
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 16
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 15
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 14
16/10/10 14:48:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 14:48:55 INFO ContextCleaner: Cleaned accumulator 13
16/10/10 14:48:56 INFO FileInputFormat: Total input paths to process : 1
16/10/10 14:48:56 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:-2
16/10/10 14:48:56 INFO DAGScheduler: Registering RDD 60 (sql at NativeMethodAccessorImpl.java:-2)
16/10/10 14:48:56 INFO DAGScheduler: Got job 12 (sql at NativeMethodAccessorImpl.java:-2) with 1 output partitions
16/10/10 14:48:56 INFO DAGScheduler: Final stage: ResultStage 13 (sql at NativeMethodAccessorImpl.java:-2)
16/10/10 14:48:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
16/10/10 14:48:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
16/10/10 14:48:56 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[60] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/10/10 14:48:56 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 21.4 KB, free 249.2 KB)
16/10/10 14:48:56 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 9.5 KB, free 258.7 KB)
16/10/10 14:48:56 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:51185 (size: 9.5 KB, free: 511.1 MB)
16/10/10 14:48:56 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[60] at sql at NativeMethodAccessorImpl.java:-2)
16/10/10 14:48:56 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
16/10/10 14:48:56 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2467 bytes)
16/10/10 14:48:56 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2467 bytes)
16/10/10 14:48:56 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
16/10/10 14:48:56 INFO Executor: Running task 1.0 in stage 12.0 (TID 13)
16/10/10 14:48:56 INFO CacheManager: Partition rdd_57_0 not found, computing it
16/10/10 14:48:56 INFO CacheManager: Partition rdd_57_1 not found, computing it
16/10/10 14:48:56 INFO HadoopRDD: Input split: file:/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/RtmpI3wuED/file196a6e82aeb4.csv:0+651
16/10/10 14:48:56 INFO HadoopRDD: Input split: file:/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/RtmpI3wuED/file196a6e82aeb4.csv:651+652
16/10/10 14:48:56 INFO GenerateUnsafeProjection: Code generated in 18.624923 ms
16/10/10 14:48:56 INFO MemoryStore: Block rdd_57_1 stored as values in memory (estimated size 2.8 KB, free 261.5 KB)
16/10/10 14:48:56 INFO BlockManagerInfo: Added rdd_57_1 in memory on localhost:51185 (size: 2.8 KB, free: 511.1 MB)
16/10/10 14:48:56 INFO MemoryStore: Block rdd_57_0 stored as values in memory (estimated size 2.8 KB, free 264.3 KB)
16/10/10 14:48:56 INFO BlockManagerInfo: Added rdd_57_0 in memory on localhost:51185 (size: 2.8 KB, free: 511.1 MB)
16/10/10 14:48:56 INFO GeneratePredicate: Code generated in 3.08383 ms
16/10/10 14:48:56 INFO GenerateColumnAccessor: Code generated in 16.74614 ms
16/10/10 14:48:56 INFO GenerateMutableProjection: Code generated in 6.099185 ms
16/10/10 14:48:56 INFO GenerateUnsafeProjection: Code generated in 5.694414 ms
16/10/10 14:48:56 INFO GenerateMutableProjection: Code generated in 13.884474 ms
16/10/10 14:48:56 INFO GenerateUnsafeRowJoiner: Code generated in 5.688506 ms
16/10/10 14:48:56 INFO GenerateUnsafeProjection: Code generated in 8.982582 ms
16/10/10 14:48:56 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 4031 bytes result sent to driver
16/10/10 14:48:56 INFO Executor: Finished task 1.0 in stage 12.0 (TID 13). 4031 bytes result sent to driver
16/10/10 14:48:56 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 13) in 430 ms on localhost (1/2)
16/10/10 14:48:56 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 432 ms on localhost (2/2)
16/10/10 14:48:56 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
16/10/10 14:48:56 INFO DAGScheduler: ShuffleMapStage 12 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.433 s
16/10/10 14:48:56 INFO DAGScheduler: looking for newly runnable stages
16/10/10 14:48:56 INFO DAGScheduler: running: Set()
16/10/10 14:48:56 INFO DAGScheduler: waiting: Set(ResultStage 13)
16/10/10 14:48:56 INFO DAGScheduler: failed: Set()
16/10/10 14:48:56 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/10/10 14:48:56 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 9.3 KB, free 273.6 KB)
16/10/10 14:48:56 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KB, free 278.2 KB)
16/10/10 14:48:56 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:51185 (size: 4.6 KB, free: 511.1 MB)
16/10/10 14:48:56 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:-2)
16/10/10 14:48:56 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
16/10/10 14:48:56 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, partition 0,NODE_LOCAL, 2290 bytes)
16/10/10 14:48:56 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
16/10/10 14:48:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/10/10 14:48:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/10/10 14:48:56 INFO GenerateMutableProjection: Code generated in 5.797689 ms
16/10/10 14:48:56 INFO GenerateMutableProjection: Code generated in 5.44327 ms
16/10/10 14:48:56 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1830 bytes result sent to driver
16/10/10 14:48:56 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 119 ms on localhost (1/1)
16/10/10 14:48:56 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
16/10/10 14:48:56 INFO DAGScheduler: ResultStage 13 (sql at NativeMethodAccessorImpl.java:-2) finished in 0.119 s
16/10/10 14:48:56 INFO DAGScheduler: Job 12 finished: sql at NativeMethodAccessorImpl.java:-2, took 0.602129 s
16/10/10 14:48:57 INFO ParseDriver: Parsing command: SELECT count(*) FROM `mtcars`
16/10/10 14:48:58 INFO ParseDriver: Parse Completed
16/10/10 14:48:58 INFO SparkContext: Starting job: collect at utils.scala:181
16/10/10 14:48:58 INFO DAGScheduler: Registering RDD 67 (collect at utils.scala:181)
16/10/10 14:48:58 INFO DAGScheduler: Got job 13 (collect at utils.scala:181) with 1 output partitions
16/10/10 14:48:58 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:181)
16/10/10 14:48:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
16/10/10 14:48:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
16/10/10 14:48:58 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[67] at collect at utils.scala:181), which has no missing parents
16/10/10 14:48:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 21.4 KB, free 299.6 KB)
16/10/10 14:48:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.5 KB, free 309.2 KB)
16/10/10 14:48:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:51185 (size: 9.5 KB, free: 511.1 MB)
16/10/10 14:48:58 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[67] at collect at utils.scala:181)
16/10/10 14:48:58 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
16/10/10 14:48:58 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2467 bytes)
16/10/10 14:48:58 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2467 bytes)
16/10/10 14:48:58 INFO Executor: Running task 1.0 in stage 14.0 (TID 16)
16/10/10 14:48:58 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
16/10/10 14:48:58 INFO BlockManager: Found block rdd_57_0 locally
16/10/10 14:48:58 INFO BlockManager: Found block rdd_57_1 locally
16/10/10 14:48:58 INFO Executor: Finished task 1.0 in stage 14.0 (TID 16). 2679 bytes result sent to driver
16/10/10 14:48:58 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 2679 bytes result sent to driver
16/10/10 14:48:58 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 16) in 15 ms on localhost (1/2)
16/10/10 14:48:58 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 15 ms on localhost (2/2)
16/10/10 14:48:58 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
16/10/10 14:48:58 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:181) finished in 0.016 s
16/10/10 14:48:58 INFO DAGScheduler: looking for newly runnable stages
16/10/10 14:48:58 INFO DAGScheduler: running: Set()
16/10/10 14:48:58 INFO DAGScheduler: waiting: Set(ResultStage 15)
16/10/10 14:48:58 INFO DAGScheduler: failed: Set()
16/10/10 14:48:58 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[70] at collect at utils.scala:181), which has no missing parents
16/10/10 14:48:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.4 KB, free 318.6 KB)
16/10/10 14:48:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 323.2 KB)
16/10/10 14:48:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:51185 (size: 4.6 KB, free: 511.1 MB)
16/10/10 14:48:58 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
16/10/10 14:48:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[70] at collect at utils.scala:181)
16/10/10 14:48:58 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
16/10/10 14:48:58 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17, localhost, partition 0,NODE_LOCAL, 2290 bytes)
16/10/10 14:48:58 INFO Executor: Running task 0.0 in stage 15.0 (TID 17)
16/10/10 14:48:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/10/10 14:48:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/10/10 14:48:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 17). 1830 bytes result sent to driver
16/10/10 14:48:58 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 7 ms on localhost (1/1)
16/10/10 14:48:58 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
16/10/10 14:48:58 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:181) finished in 0.007 s
16/10/10 14:48:58 INFO DAGScheduler: Job 13 finished: collect at utils.scala:181, took 0.063069 s
16/10/10 14:48:58 INFO ParseDriver: Parsing command: SELECT *
FROM `mtcars` AS `zzz1`
WHERE (0 = 1)
16/10/10 14:48:58 INFO ParseDriver: Parse Completed
16/10/10 14:48:58 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:48:58 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:49:06 INFO ParseDriver: Parsing command: SELECT * FROM mtcars LIMIT 5
16/10/10 14:49:06 INFO ParseDriver: Parse Completed
16/10/10 14:49:06 INFO SparkContext: Starting job: collect at utils.scala:181
16/10/10 14:49:06 INFO DAGScheduler: Got job 14 (collect at utils.scala:181) with 1 output partitions
16/10/10 14:49:06 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:181)
16/10/10 14:49:06 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:49:06 INFO DAGScheduler: Missing parents: List()
16/10/10 14:49:06 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[74] at collect at utils.scala:181), which has no missing parents
16/10/10 14:49:06 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.1 KB, free 340.3 KB)
16/10/10 14:49:06 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.7 KB, free 348.0 KB)
16/10/10 14:49:06 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:51185 (size: 7.7 KB, free: 511.1 MB)
16/10/10 14:49:06 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
16/10/10 14:49:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[74] at collect at utils.scala:181)
16/10/10 14:49:06 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
16/10/10 14:49:06 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2478 bytes)
16/10/10 14:49:06 INFO Executor: Running task 0.0 in stage 16.0 (TID 18)
16/10/10 14:49:06 INFO BlockManager: Found block rdd_57_0 locally
16/10/10 14:49:06 INFO GenerateColumnAccessor: Code generated in 35.683352 ms
16/10/10 14:49:06 INFO GenerateSafeProjection: Code generated in 8.913326 ms
16/10/10 14:49:06 INFO Executor: Finished task 0.0 in stage 16.0 (TID 18). 3357 bytes result sent to driver
16/10/10 14:49:06 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 80 ms on localhost (1/1)
16/10/10 14:49:06 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:181) finished in 0.080 s
16/10/10 14:49:06 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
16/10/10 14:49:06 INFO DAGScheduler: Job 14 finished: collect at utils.scala:181, took 0.088374 s
16/10/10 14:49:13 INFO ParseDriver: Parsing command: SELECT * FROM array.dfs LIMIT 5
16/10/10 14:49:13 INFO ParseDriver: Parse Completed
16/10/10 14:49:13 INFO HiveMetaStore: 0: get_table : db=array tbl=dfs
16/10/10 14:49:13 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_table : db=array tbl=dfs	
16/10/10 14:49:16 INFO ParseDriver: Parsing command: SELECT * FROM mtcars LIMIT 5
16/10/10 14:49:16 INFO ParseDriver: Parse Completed
16/10/10 14:49:16 INFO SparkContext: Starting job: collect at utils.scala:181
16/10/10 14:49:16 INFO DAGScheduler: Got job 15 (collect at utils.scala:181) with 1 output partitions
16/10/10 14:49:16 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:181)
16/10/10 14:49:16 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:49:16 INFO DAGScheduler: Missing parents: List()
16/10/10 14:49:16 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[77] at collect at utils.scala:181), which has no missing parents
16/10/10 14:49:16 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 17.1 KB, free 365.1 KB)
16/10/10 14:49:16 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.7 KB, free 372.8 KB)
16/10/10 14:49:16 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:51185 (size: 7.7 KB, free: 511.1 MB)
16/10/10 14:49:16 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
16/10/10 14:49:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[77] at collect at utils.scala:181)
16/10/10 14:49:16 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
16/10/10 14:49:16 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 19, localhost, partition 0,PROCESS_LOCAL, 2478 bytes)
16/10/10 14:49:16 INFO Executor: Running task 0.0 in stage 17.0 (TID 19)
16/10/10 14:49:16 INFO BlockManager: Found block rdd_57_0 locally
16/10/10 14:49:16 INFO Executor: Finished task 0.0 in stage 17.0 (TID 19). 3357 bytes result sent to driver
16/10/10 14:49:16 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 19) in 7 ms on localhost (1/1)
16/10/10 14:49:16 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:181) finished in 0.007 s
16/10/10 14:49:16 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
16/10/10 14:49:16 INFO DAGScheduler: Job 15 finished: collect at utils.scala:181, took 0.018046 s
16/10/10 14:49:39 INFO ParseDriver: Parsing command: SELECT * FROM mtcars LIMIT 5
16/10/10 14:49:39 INFO ParseDriver: Parse Completed
16/10/10 14:49:39 INFO SparkContext: Starting job: collect at utils.scala:181
16/10/10 14:49:39 INFO DAGScheduler: Got job 16 (collect at utils.scala:181) with 1 output partitions
16/10/10 14:49:39 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:181)
16/10/10 14:49:39 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:49:39 INFO DAGScheduler: Missing parents: List()
16/10/10 14:49:39 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[80] at collect at utils.scala:181), which has no missing parents
16/10/10 14:49:39 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 17.1 KB, free 389.9 KB)
16/10/10 14:49:39 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.7 KB, free 397.6 KB)
16/10/10 14:49:39 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:51185 (size: 7.7 KB, free: 511.1 MB)
16/10/10 14:49:39 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
16/10/10 14:49:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[80] at collect at utils.scala:181)
16/10/10 14:49:39 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
16/10/10 14:49:39 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2478 bytes)
16/10/10 14:49:39 INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
16/10/10 14:49:39 INFO BlockManager: Found block rdd_57_0 locally
16/10/10 14:49:39 INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 3357 bytes result sent to driver
16/10/10 14:49:39 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 8 ms on localhost (1/1)
16/10/10 14:49:39 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:181) finished in 0.008 s
16/10/10 14:49:39 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
16/10/10 14:49:39 INFO DAGScheduler: Job 16 finished: collect at utils.scala:181, took 0.018473 s
16/10/10 14:50:15 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:50:15 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:50:15 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:50:15 INFO DAGScheduler: Got job 17 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:50:15 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:59)
16/10/10 14:50:15 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:50:15 INFO DAGScheduler: Missing parents: List()
16/10/10 14:50:15 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[84] at map at utils.scala:56), which has no missing parents
16/10/10 14:50:15 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 5.4 KB, free 403.0 KB)
16/10/10 14:50:15 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.0 KB, free 406.0 KB)
16/10/10 14:50:15 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:50:15 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
16/10/10 14:50:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[84] at map at utils.scala:56)
16/10/10 14:50:15 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
16/10/10 14:50:15 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 21, localhost, partition 0,PROCESS_LOCAL, 2739 bytes)
16/10/10 14:50:15 INFO Executor: Running task 0.0 in stage 19.0 (TID 21)
16/10/10 14:50:15 INFO Executor: Finished task 0.0 in stage 19.0 (TID 21). 1081 bytes result sent to driver
16/10/10 14:50:15 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 21) in 4 ms on localhost (1/1)
16/10/10 14:50:15 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
16/10/10 14:50:15 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:50:15 INFO DAGScheduler: Job 17 finished: collect at utils.scala:59, took 0.013079 s
16/10/10 14:50:15 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:50:15 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:50:15 INFO SparkContext: Starting job: collect at utils.scala:59
16/10/10 14:50:15 INFO DAGScheduler: Got job 18 (collect at utils.scala:59) with 1 output partitions
16/10/10 14:50:15 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:59)
16/10/10 14:50:15 INFO DAGScheduler: Parents of final stage: List()
16/10/10 14:50:15 INFO DAGScheduler: Missing parents: List()
16/10/10 14:50:15 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[88] at map at utils.scala:56), which has no missing parents
16/10/10 14:50:15 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 5.4 KB, free 411.4 KB)
16/10/10 14:50:15 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.0 KB, free 414.4 KB)
16/10/10 14:50:15 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:51185 (size: 3.0 KB, free: 511.0 MB)
16/10/10 14:50:15 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
16/10/10 14:50:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[88] at map at utils.scala:56)
16/10/10 14:50:15 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
16/10/10 14:50:15 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2739 bytes)
16/10/10 14:50:15 INFO Executor: Running task 0.0 in stage 20.0 (TID 22)
16/10/10 14:50:15 INFO Executor: Finished task 0.0 in stage 20.0 (TID 22). 1081 bytes result sent to driver
16/10/10 14:50:15 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 22) in 3 ms on localhost (1/1)
16/10/10 14:50:15 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
16/10/10 14:50:15 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:59) finished in 0.005 s
16/10/10 14:50:15 INFO DAGScheduler: Job 18 finished: collect at utils.scala:59, took 0.012519 s
16/10/10 14:50:15 INFO HiveMetaStore: 0: get_tables: db=default pat=.*
16/10/10 14:50:15 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
16/10/10 14:50:15 INFO HiveMetaStore: 0: get_table : db=array tbl=df
16/10/10 14:50:15 INFO audit: ugi=danny	ip=unknown-ip-addr	cmd=get_table : db=array tbl=df	
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.0 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 52
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 51
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:51185 in memory (size: 3.0 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 50
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 49
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:51185 in memory (size: 7.7 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 48
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:51185 in memory (size: 7.7 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 47
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:51185 in memory (size: 7.7 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 46
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:51185 in memory (size: 4.6 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 45
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:51185 in memory (size: 9.5 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 44
16/10/10 15:08:51 INFO ContextCleaner: Cleaned shuffle 1
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:51185 in memory (size: 4.6 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 35
16/10/10 15:08:51 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:51185 in memory (size: 9.5 KB, free: 511.1 MB)
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 34
16/10/10 15:08:51 INFO ContextCleaner: Cleaned shuffle 0
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 33
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 32
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 31
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 30
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 29
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 28
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 27
16/10/10 15:08:51 INFO ContextCleaner: Cleaned accumulator 26
16/10/10 15:36:40 INFO SparkContext: Invoking stop() from shutdown hook
16/10/10 15:36:41 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
16/10/10 15:36:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/10/10 15:36:41 INFO MemoryStore: MemoryStore cleared
16/10/10 15:36:41 INFO BlockManager: BlockManager stopped
16/10/10 15:36:41 INFO BlockManagerMaster: BlockManagerMaster stopped
16/10/10 15:36:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/10/10 15:36:41 INFO SparkContext: Successfully stopped SparkContext
16/10/10 15:36:41 INFO ShutdownHookManager: Shutdown hook called
16/10/10 15:36:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-a6d44dfe-a9bb-4701-9ece-827899d76ce3
16/10/10 15:36:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/10/10 15:36:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/10/10 15:36:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f/httpd-6db5af73-6676-4d15-b5cb-b8df8c94bc47
16/10/10 15:36:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/_w/jdnf5prj6tx_lhwn49sjhr280000gn/T/spark-8e67d418-cced-4a46-87e4-3d44ffc11b0f
16/10/10 15:36:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
